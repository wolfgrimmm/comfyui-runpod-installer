
Please register for RunPod at: https://get.runpod.io/955rkuppqv4h

Example tutorial for learn how to install and use RunPod is below

(starts at 22:03) : https://youtu.be/KW-MHmoNcqo?si=QN8X8Sjn13ZYu-EU&t=1323

RunPod permanent network storage tutorial : https://youtu.be/8Qf4x3-DFf4

When deploying a Pod select min 24 GB GPU like RTX 3090 but 4090 should work way faster or 5090 even better

Recommended GPUs are 48 GB for maximum speed A40, A6000, L40S or RTX 6000 PRO

select runpod template - this is important

RunPod Pytorch 2.2.0
runpod/pytorch:2.2.0-py3.10-cuda12.1.1

Edit Template

Make volume disk 100 gb or bigger - this is important

Add expose HTTP ports 7861 to connect via proxy if you want but i recommend Gradio share

It will by defualt start with --share with gradio share as well

Upload everything into workspace folder - you can upload zip file and extract it as well

To install run below command

pip install huggingface_hub
export HF_HOME="/workspace"
chmod +x RunPod_Install_Ovi.sh
./RunPod_Install_Ovi.sh

The installer will auto download models. But if you get any error after, run below command and it will resume download and fix errors

cd /workspace
python Download_Models.py

To run the app again after installation later run below command - installation will auto start the app so use this later for re-starting the app

cd /workspace/Ovi_Pro
git pull
source venv/bin/activate
unset LD_LIBRARY_PATH
export PYTHONWARNINGS=ignore
python premium.py --share




If you want to rent a machine with multiple GPUs you can follow following strategy

So with below strategy we limit started app to GPU 1 and changing default output dir so wont overwrite each other


cd /workspace/Ovi_Pro
git pull
source venv/bin/activate
export CUDA_VISIBLE_DEVICES=1
unset LD_LIBRARY_PATH
export PYTHONWARNINGS=ignore
python premium.py --share --output_dir "/workspace/Ovi_Pro/outputs1"